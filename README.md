# Journal-week-4
Here it is, week number 4! You know the drill, first you'll see the things I did in the week, then you'll see about the videos and lecture of this weeks' assignments. The monthly review, along with the books and course, will be in another repository. So....here we go!

## October 19

New week!! Alright, I managed to get the videos and resume of the week out of the way, so I could focus on the Movie recommender problem. Wow…..I banged my head a few times trying to solve the issues, but I think I managed to do it!! As I’m writing right now, I just need to make a Pull Request. This series of steps keep avoiding me, because I can’t get the hold of what exactly I’m doing. I’ll ask one of my teammates, so we’ll both do the pull request at the same time, helping each other  along the way.  I just need to finish editing my resume in Github, and I’ll just have to wait for the new tasks of this week!
I entered the Lightning Talks of my teammates (there were some issues, so one of the talks couldn’t be completed), consisting in:
* Composition.
* VIM Basics.
* Lazy Load.
* Rubber duck debugging.

Interesting topic de rubber duck one. It’s a good method to debug your code, where you explain the whole problem, and then you proceed to solve it. The very simple technique of explaining something to someone may help to see where your current block is! Explaining something out loud makes your thinking slow down, so you can break down every piece of information.  It then develops our reasoning. In application to programming, explaining our process breaks our ego, -thinking we’re doing it right-. With this, you gain the opportunity to learn from your mistakes. Remember, it’s all about learning.

## October 20

I had the opportunity to meet with one of my mentors (and I’ll see the other one later). The talk was about how I solved the programming problem last week. It was very interesting to see his opinions and points of view, because there were some reasoning parts where I had to think about everything I did. I told him that I didn’t quite feel an expert in programming, for many reasons. The answer was that it was alright. Yes, the Academy expects from me that I can develop this ability, but right now the main objective was that I could find and solve the problem! 
Of course, the problem was hard, and as I’ve said before in other writings of mine, I had support with my teammates and the internet. Some things I just had to “go with the flow”, like using Hashmaps instead of Lists: this was because some of my perks said that lists made the program go slow, so I didn’t want to check that by myself. 
It was a great talk, because I did the rubber duck technique! As I explained my code, my head started to get a better understanding of some implementations! It’s a technique that I want to develop, because I felt good about my knowledge after we finished the meeting.

The lightning talks of today were:
* SOLID.
* Unit Testing.
* The struggle of creativity.
* Docker.
* React, Angular, Vue

The docker presentation one gave me an interesting topic, the Packaging. It basically means that your work should be able to work in any environment, not just in your own computer. This is a great feature to have, because you won’t have any problem when trying to use your work in a different environment. I believe that this would be a must-have feature, but again, it may be hard to make 1 project work in different environments, so the easy choice is to just change the project and leave the main tools as they are.

## October 21

I had good pair programming with one of my mentors. I liked a lot of all of the things he made, I could see some of the code he has, many of the things that he makes work look great! Of course, there are so many things that I don’t know, I’m no expert, but I think this is the correct way, to start getting familiar with the environment of work, at least in Back-End programming! I managed to point out a step that my mentor skipped, and he told me that it was a great comment from my part! Do not think that it was a big mistake that I pointed out, but this little situation was perfect so that my mentor could explain to me the importance of these pair programming sessions: many times, giving ideas on a problem can be very helpful, because these ideas come from different angles, different perspectives. While your perspective may see the problem and solution of something, you may have problems looking for some other solutions, or a different understanding of a problem. This is where the other opinions come, and you have to be open minded to accept them, not immediately deny them. I’ve also learned about some concepts, like DAO (Data Access Object). I even got to know more about Sky Touch, which is one of the main clients here in Encora.
I had the opportunity to go to the Lightning Talks, which were:
* Communication in the times of remote work.
* Deno.
* Caching.
* Manual QA.
* Linear algebra from ML.
* Test Driven Development.
* Dependencies.

I liked the very first one! I liked the steps my perk said, like quickly adapting to something, checking constantly on the work of your team (and yours too). Of course, it’s important to have good software for this kind of remote work. Another interesting thing he said was about getting the information. Because of the current situation, we need to work mostly on computers, and because of that, most of the information we get is through our eyes (visual information). This is a great opportunity to develop this ability, to give information this way!
Creating company culture….but online. Seems hard, and I personally believe that this is possible because Encora already had this culture in its employees, so it was easier to keep this culture, rather than creating it. Nevertheless, it’s great that Encora manages to keep this culture even with the pandemic situation!
I also liked the Manual QA. You need to establish the goals, the requirements of your project. This includes the limitations. Then you go to the Daily Activities, where you do your stand up, talk about your tickets, work on your development of test cases, validation and verification of any fix that you’ve checked or did.
Remember, manual QA seek for the product quality, and not just try to find errors, nor blame the developer, they are not the developers’ enemies. The tester needs to be very patient, creative and be open minded to be able to find any possible solution or suggestion to the project.

## October 22


Well...Today I was the victim of Murphy’s Law, so I couldn’t do many things in the morning. Still, the day has just started!
Luckily, I managed to enter the Lightning Talks, which were:
* Procrastination.
* Artificial Vision.
* Object Oriented Programming.
* Public Key Encryption.

I find myself somehow identified with the procrastination one, because I sometimes do that! I believe that these few weeks in the Academy I managed to work on this topic, so now I’m a more productive person. Of course, it’s not that I’m now an expert and everything I do I complete it on that day. I still rest when I should be working, or distract myself with something, but the frequency of these actions is slowing at a fast pace!, It’s a working process for me, and I think I’m in a great rhythm to totally change this mentality.
The public key presentation was very interesting. When you want to protect an information, you should encrypt it. This is basically encode and decode the information. First, you get the text, then you encrypt and decrypt it with the same key, between them you cipher-text the information, so that after the decrypt parte, you can get the text again.
The public key encryption is a good technique for this topic, because it solves the problem of using just 1 key in the encryption of the text: instead, it uses 2, securing the information that you have.

## October 23

Today I didn’t meet with any of my mentors, but it was a great opportunity to put some details into my presentation, and practice it! It was also a good opportunity to make the sketches of the things I’ve learned this month. You start to think how even when it’s a small amount of time, you start to notice some changes in your way of working. At first I was a little scared of entering the Academy, because it’s a whole new world for me! There are many concepts and definitions that may be normal to another person, but for me it represents a whole pack of information, and I have to carefully unwrap it so I can process the information in an efficient way.


## Videos


### Seth Lloyd on Programming the Universe

This video centers on the computational power of atoms, electrons and elementary particles. How, you may ask, well, it’s a similar concept on how you get ideas: they build up on previous generations of their cells, meaning that they learn from the “mistakes” from their past cells. This starts to go related with computers and bits (specially the bit part). Every particle in the universe has a bit of information, just like the information that goes through computers. This is an analogy of how everything works. As I’ve said, every particle has its own information (bit sized), and every interaction that this particle has makes the bit flip, from one value to another.
You may start wondering “so what?”, but it is important to keep this in mind, because the video tells us about the meaning of information that you may have. It’s not the same having a lot of information about something, and not knowing what it is about, than having less information, but perfectly knowing the meaning of it.
This is where the computers come into action. A computer gets bits, and does something based on the bit (because it understands it). But this bit only has that information, and it can't do anything else...sounds like a waste of resources right? It is, at least for me. Luckily (or unluckily, because I don’t comprehend it), there’s quantum computers, where they have the superposition feature, and it can register both the 0 and 1 information at the same time. You could say it’s multitasking! And at first, this may be easy, but the more bits you have, the more complicated it gets. Using these kinds of computers is to check the capabilities of the universe while computing.
The universe is constantly expanding, and constantly growing, and it is doing it because of tiny molecules being injected in front of it. This may be the explanation of why we’re here, because the universe managed to work with these molecules and compute them. In a similar way, we must work with the quantum particles, so we can keep expanding.

### Seth Lloyd: Quantum Machine Learning 

This is a similar video to the last one, where the presenter gives almost the same explanation and examples to explain the quantum world. It does add that explaining Quantum physics tends to be hard, because it’s usually against the normal intuition that we have in our classic physics world. 
Usually, algorithms in Machine Learning are executed on normal computers, but it’s becoming a problem of limitation when using these kinds of computers, because of a similar example in the last video. While a classic computer can only handle one value of a bit (and its information), a quantum computer can manage both bits, and even more!
While ML algorithms are used to compute immense quantities of data, the quantum machine learning increases such capabilities intelligently, by creating opportunities to conduct analysis on quantum states and systems. This can be complex in nature, but this is executed faster with the assistance of quantum devices.
This may be only my opinion, but we ARE reaching limits in a lot of investigations. This could be considered in the future as an inflexion point in history, where humanity starts using more quantum devices, and who knows….maybe by doing that, we’ll start comprehending this subject better, and thus, start creating more devices, based on these principles.

### Why We Should Have Your Own Black Box?

I think this was my favorite video, because I’ve been in contact with the example that the presenter gives when comparing pilots (the doctors). Warning, I’m not saying that the doctors are wrong with their methods, it’s a different perspective. I’m an engineer, I handle machines and computers. Doctors handle the life of real people. I can see the errors that they make, but it’s an opinion coming from the exterior of that group...I wonder if my mind would change if I were a doctor...Anyhow, let’s get right into it! The main concept that this video gives us is about acknowledging your own failure and confronting your mistakes. Talent isn’t enough, and your commitment to keep improving is very important, so don’t be scared! This goes to comparing a pilot with a doctor. If there’s an accident in a plane, they retrieve the black boxes, so that they can see where the failure happened, and try that it never happens again. Here, you need talent, of course, but you also need constantly updating your methods, so you can keep improving. Sadly, with the doctors, you’re only considered a good one if you have the talent, it doesn’t matter if you want to improve. When facing mistakes, there are excuses just to cover themselves. And this becomes a cycle, because those mistakes, instead of trying to minimize them, they will just repeat themselves.


### Richard Feynman, The Great Explainer: Great Minds// TEDxCaltech - Tony Hey - Feynman and Computation // TEDxCaltech - Danny Hillis - Reminiscing about Richard Feynman// Feynman on Scientific Method. 

I wanted to combine all of these videos. Yes, they all have different subjects, but they all focus on the same: Richard Feynman was a superstar in almost everything! Intelligent, great sense of humor, womanizing….You can insert a certain image of a doctor that wonders if there’s something that this man can’t do!
He was a born talent, he was a very curious guy, who had the “ability” to quickly comprehend what was given to him! I think this ability was the base for everything, he learned quickly. In one of the videos they mentioned an example that Feynman read some extensive notes that the author made in six months. Well, he read (and understood) them in just 1 day...again, some talent huh? He thought differently, with another example coming in computer science. He wasn’t an expert, but with some understanding in the main topics, he managed to see the mistake of slow computers...they had a lot of energy loss on some basic features! He highlighted this mistake, and gave some possible answers to this...and bam! The energy loss was greatly minimized with these features implemented.
Of course, great talent he had, but if he were a lazy person, his name may not have been written right now. One of the people that knew him said he was such a great hard worker. Not only was he brilliant, but he wanted to keep improving constantly, which is a virtue that nowadays is so good to have. Last but not least, I want to keep a “phrase” that he said, about experimenting... “We can never be right, we can only prove we’re wrong” and that’s because of the future experiments that our own project will be tested against, they don’t yet exist, so we can’t say that we’re 100% correct.

### Stephen Wolfram: Computing a theory of everything

This may be a short essay, because I was amazed by the Wolfram page...so many different subjects in there!
We look for ways to use computers to try and connect and solve different subjects from different topics. This at first may sound hard or impossible, but you just need to break the problem into smaller problems! You can do this by creating a group of simple rules, rules that say how something is supposed to work! With this group, you can create anything!! Just remember, try that this group of rules match our physical universe, otherwise you’ll have some mighty problems when trying to unify both kinds of physics.

### The Pretotyping Manifesto 

You’ll certainly meet with the law of failures, which is basically that most new ideas will fail, even if they’re well implemented. You can’t escape from this law, but you can use it to your advantage. First, you have to make sure that you’re building the right “it” (idea to try), before you build “it” right. An innovator will always beat ideas. You need to be careful with the false positive and false negative, because you don’t actually know what an opinion could actually mean. Then, get in mind that pretotypes beat prototypes. Here, you get the “innovator’s nightmare”, where you spend a lot of time and money on your invention, just so you see that people don’t want it or don’t need it. How can you avoid this?? Well...fake it till you make it!
While in a pretotype you’ll invest hours and days, in a prototype you’ll invest days or weeks! The pretotype asks “would we use it” while the prototype asks “can we build it”. I think you’re starting to see my point.
I believe that the most important part of comparing these 2, is that when doing a pretotype you have to go with data, not opinions or ideas. Do not spend on something you’re not sure will be a success, instead, you can save that money and time with a pretotype!

### Tools for Continuous Integration at Google Scale  

We need to provide real-time information to build monitors, provide frequent green builds for cutting releases and develop all of the projects safely. Some tips for this is to test many changes together, so that you know which change broke the build.
The benefits of this is that it identifies failures sooner, and identifies the culprit change precisely. It also lowers the compute costs, and enables teams to ship with fast iteration times.
The video tells us about developing safely by presubmitting. This makes testing available before submit, and uses fine-grained dependencies. It also avoids breaking the build.
Another important concept that it gives us is the Flaky tests. A system assumes tests pass or fail reliably with given code. Tests that don’t have this are “flaky”. This is an inability to find changes breaking the build (false positives). It’s also an inability to identify green builds for releases. You get wasted work for building monitors, and equally waste computer resources.
A solution for flaky tests? Fix them, hide them, track them down!

### Testing Engineering@Google & The Release Process for Google's Chrome for iOS  

The testing and quality of a project is about the collective effort of your teams. This also tries to look for automated tests. Of course, you need to have the balance between quality and feature velocity, so be careful when automating parts of your testing. The objective of testing is to contribute to the optimization of building, developing, testing and releasing of products.
A software engineer looks for development and release of efficiency. It is focused on testability- it refactors code to make it easier to test authoring.
A test engineer is focused on functional testing and user scenario testing. It’s basically product and user focused. This engineer tends to read and debug code and write test code.

Now, for the iOS part...the video explains that being in google is a little difficult to test these kinds of products, mostly because almost everyone uses Android! Anyhow, it starts at feature approvals at the beginning of the development cycle. Once it’s approved, they start branching their work with the rest of Chrome. It ALL needs to be approved and then get merged.
It’s usually 6 weeks of bug fixing and testing on the branch.
Of course, for all this, you need some automated tests, where bots run various channels, give fast feedback on code quality and first passes for a measure of quality. These bots have at their disposal the Unit Tests, End to end tests, Performance tests and Screenshot tests.
Even with all of these tools, you still need Manual testing, because there are some test cases that can’t be automated, or haven’t been automated yet. You also need new features that don’t have end to end tests yet.

### GTAC 2014: I Don't Test Often ... But When I Do, I Test in Production 

This video was so interesting, because it talks about how netflix is such a huge platform, that their tests go in the production, and it tends to be better! They use Unit Tests, Integration tests, Stress tests.. An exhaust test (simulates all failures) is basically impossible, because of the rapidly changing data set, and the internet having scale traffic, by naming a few issues.
It is better to cause failure deliberately to validate resiliency. Also, a test design assumptions by stressing them.Very important at this next point: do not wait for random failure. Remove this uncertainty but force it regularly.
Then, the main concept came to light...the Monkeys! Monkeys were invented to cause trouble!! It’s basically a simulation of errors and problems. You have different kinds of monkeys to create chaos in different parts. 
There are other ideas to test platforms so big, not just the monkeys!. One of them is the production code coverage, where you use real-time code usage patterns. You mainly focus testing by prioritizing frequently executed paths with low test coverage. You can also identify dead code that can be removed.
The other idea is the Canary deployments. Here, you push changes to a small number of instances. You also monitor closely to detect regressions, and you can automatically cancel deployment if problems occur.
The conclusion of all this subject is to try and look for new fail modes. This is also trying to explain the importance of making chaos testing as understood as regular regression tests, so it gets more used in the future.

### GTAC 2014: Test coverage at Google  

In Google they work a little different, because before the check in there is a code review. It has small, incremental changes to make it efficient. It’s mandatory, and it’s enforced by tools, with an automated analysis.
The code should be accompanied by tests. It also needs coverage! There are different kinds of coverages:
* Function (was a particular function called?).
* Statement (was a particular line of code executed?).
* Branch (Was an edge in the program executed?).
* Other (Increasingly expensive to calculate).

Last but not least, there are 2 ways of testing:
* Per-project (At least once per day).
* Per-commit (On each commit).

### GTAC 2014: The Testing User Experience 

Testing tends to be a hard problem. In the particular case of Google, they have a lot of products, and they try that every single one of them has no flaws. How can they do that? Well, continuous delivery means more testing, and more testing means more test maintenance, all while trying to solve the user’s problem.
For this, they need test tools that engineers actually want to use! Of course, these tools need to keep the build green with less maintenance work. So it comes a Breakage, where there are some points:
* Do we need a human to take action?
* Find the right assignee, and route communication.
* Explain the problem, and likely causes.
* Success metric: How quickly it was resolved.
This can be managed with:
* Calls to action (check error).
* Coordination and Expert Help.
* Resolve the issue (Back to work).
* Check the root cause.

After all of these steps, you get the test result, which is a complete representation of the results of a test. It lets the engineer find the root cause more quickly.

### Breaking Things at Netflix

The video starts with a powerful phrase: “You’re going to have failures, whether you do them on purpose or not, so you should question ‘is your system going to handle it well and what is going to occur’”. You need to vaccinate yourself with failure NOW, so you get prepared in the future (with no failure).
All of this is so that it becomes easier to do the right thing in your project. Even so, be careful! Always have a plan B!! It’s just in case you need to go back to square 1.


## Lecture

### Chaos Engineering: the history, principles, and practice

What a great lecture this was! Failures have become hard to predict...Here’s where Chaos comes! The chaos engineering….it’s like a preventive medicine. It’s a disciplined approach to identifying failures before they become outages. You need to break things on purpose to learn how to build more resilient systems. For this, you have 3 steps:
* Plan on experiment (Hypothesis).
* Contain blast radius (Execute the smallest test that will teach you something of your project).
* Scale or squash (Find an issue? Good. Otherwise, increase the blast radius until you’re at full scale).

The plan for chaos has these steps and implements some more:
* Plan your experiment (what could go wrong).
* Create a Hypothesis (think an expected outcome).
* Measure the impact (check the availability and durability of your system).
* Have a back up plan (how to revert the impact).
* Fix it! (Check for resilience or fix the problem found).
* Have fun (seriously, it makes the chaos job easier to make).

Remember, systems have grown much more complex. Failures have become more difficult to predict, so you need to be proactive in your efforts to learn from these failures (and of course, identify them).

That'ss it for this week! I don-t know if there'll be another entry for this...either way, you know where to find me if you have any questions!
